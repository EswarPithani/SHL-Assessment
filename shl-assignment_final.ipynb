{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":97919,"databundleVersionId":11694977,"sourceType":"competition"},{"sourceId":11283469,"sourceType":"datasetVersion","datasetId":7054703}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"üß† Grammar Scoring Engine using Whisper + BERT\n\nThis project implements a Grammar Scoring Engine for spoken English audio using OpenAI Whisper for transcription and a fine-tuned BERT regressor for grammar quality prediction. The system evaluates spoken sentences and outputs a Mean Opinion Score (MOS) between 0 and 5, based on grammar correctness.\n\nüöÄ Model Pipeline Overview\n\nASR (Automatic Speech Recognition)\n\nUses OpenAI Whisper (various model sizes supported) to convert audio to text.\n\nText Embedding + Regression\n\nUses a BERT-based regression model fine-tuned on transcribed text to predict the grammar score.\n\nEvaluation\n\nModel is trained using K-Fold Cross Validation.\n\nEvaluation metric: Pearson Correlation Coefficient.\n\nüß™ Results Model: Whisper (small) + BERT Regressor\n\nTraining Epochs: 10\n\nK-Fold Splits: 5\n\nBest Pearson Score: 0.778\n\nüß∞ Requirements Python 3.10+\n\nPyTorch\n\nTransformers (HuggingFace)\n\nOpenAI Whisper\n\nLibrosa\n\nScikit-learn\n\nPandas, Numpy, tqdm\n\nüîÅ Training Details 5-Fold Cross Validation using KFold\n\nFine-tuning bert-base-uncased on text transcripts\n\nLoss Function: MSELoss\n\nOptimizer: AdamW\n\nOutputs clipped between [0, 5]\n\nüôå Acknowledgements\n\nOpenAI Whisper\n\nHuggingFace Transformers\n\nOrganizers of the Grammar Scoring Competition\n\n","metadata":{}},{"cell_type":"code","source":"!pip install -q transformers datasets torchaudio librosa sentencepiece accelerate\n!pip install -q git+https://github.com/openai/whisper.git\n!pip install -U openai-whisper","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"****Importing the required Modules****","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport torch\nimport librosa\nimport whisper\nfrom tqdm import tqdm\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nfrom scipy.stats import pearsonr\nfrom transformers import BertTokenizer, BertModel, BertConfig\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom transformers import AdamW\nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**2. Loading the Dataset**","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/shl-dataset/dataset/train.csv')\ntest_df = pd.read_csv('/kaggle/input/shl-dataset/dataset/test.csv')\nsubmission_df = pd.read_csv('/kaggle/input/shl-dataset/dataset/sample_submission.csv')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(train_df.columns)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"****3. Using whisper for Transcribe****","metadata":{}},{"cell_type":"code","source":"whisper_model = whisper.load_model(\"large-v2\")\n\ndef transcribe(audio_path):\n    result = whisper_model.transcribe(audio_path, fp16=False)\n    return result['text']\n\ntrain_transcripts = []\nfor fname in tqdm(train_df['filename']):\n    path = f\"/kaggle/input/shl-dataset/dataset/audios_train/{fname}\"\n    try:\n        text = transcribe(path)\n    except:\n        text = \"\"\n    train_transcripts.append(text)\ntrain_df['transcript'] = train_transcripts\n\ntest_transcripts = []\nfor fname in tqdm(test_df['filename']):\n    path = f\"/kaggle/input/shl-dataset/dataset/audios_test/{fname}\"\n    try:\n        text = transcribe(path)\n    except:\n        text = \"\"\n    test_transcripts.append(text)\ntest_df['transcript'] = test_transcripts","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"****4. Tokenization with BERT****","metadata":{}},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n\nclass GrammarDataset(Dataset):\n    def __init__(self, texts, targets=None):\n        self.encodings = tokenizer(texts, padding=True, truncation=True, max_length=256, return_tensors=\"pt\")\n        self.targets = targets\n\n    def __len__(self):\n        return len(self.encodings['input_ids'])\n\n    def __getitem__(self, idx):\n        item = {key: val[idx] for key, val in self.encodings.items()}\n        if self.targets is not None:\n            item['labels'] = torch.tensor(self.targets[idx], dtype=torch.float)\n        return item","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**5. BERT Regression Model**","metadata":{}},{"cell_type":"code","source":"class BERTRegressor(nn.Module):\n    def __init__(self):\n        super(BERTRegressor, self).__init__()\n        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n        self.regressor = nn.Linear(self.bert.config.hidden_size, 1)\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        cls_output = outputs.pooler_output\n        return self.regressor(cls_output).squeeze(1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"****6. K-Fold Training****","metadata":{}},{"cell_type":"code","source":"kf = KFold(n_splits=10, shuffle=True, random_state=42)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nEPOCHS = 20\nfold = 0\nall_val_preds = []\nall_val_labels = []\ntrain_losses, val_pearsons = [], []\n\nfor train_index, val_index in kf.split(train_df):\n    fold += 1\n    print(f\"\\n----- Fold {fold} -----\")\n    train_texts = train_df.iloc[train_index]['transcript'].tolist()\n    val_texts = train_df.iloc[val_index]['transcript'].tolist()\n    train_targets = train_df.iloc[train_index]['label'].tolist()\n    val_targets = train_df.iloc[val_index]['label'].tolist()\n\n    train_dataset = GrammarDataset(train_texts, train_targets)\n    val_dataset = GrammarDataset(val_texts, val_targets)\n\n    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=8)\n\n    model = BERTRegressor().to(device)\n    optimizer = AdamW(model.parameters(), lr=2e-5)\n    criterion = nn.MSELoss()\n\n    for epoch in range(EPOCHS):\n        model.train()\n        total_loss = 0\n        for batch in train_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n\n            optimizer.zero_grad()\n            outputs = model(input_ids, attention_mask)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n\n        model.eval()\n        val_preds = []\n        val_labels = []\n        with torch.no_grad():\n            for batch in val_loader:\n                input_ids = batch['input_ids'].to(device)\n                attention_mask = batch['attention_mask'].to(device)\n                labels = batch['labels'].to(device)\n                outputs = model(input_ids, attention_mask)\n                val_preds.extend(outputs.cpu().numpy())\n                val_labels.extend(labels.cpu().numpy())\n\n        val_preds = np.clip(val_preds, 0, 5)\n        pearson = pearsonr(val_preds, val_labels)[0]\n        print(f\"Epoch {epoch+1}/{EPOCHS} - Train Loss: {total_loss:.4f} - Val Pearson: {pearson:.4f}\")\n\n        train_losses.append(total_loss)\n        val_pearsons.append(pearson)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"****7. Training Visualization****","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(train_losses)\nplt.title(\"Training Loss over Epochs\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\n\nplt.subplot(1, 2, 2)\nplt.plot(val_pearsons)\nplt.title(\"Validation Pearson Correlation\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Pearson\")\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"****8. Inference on Test Set****","metadata":{}},{"cell_type":"code","source":"# Load the sample_submission.csv to get correct column names\nsample_df = pd.read_csv(\"/kaggle/input/shl-dataset/dataset/sample_submission.csv\")\nprint(sample_df.columns)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_dataset = GrammarDataset(test_df['transcript'].tolist())\ntest_loader = DataLoader(test_dataset, batch_size=8)\n\nmodel.eval()\npredictions = []\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        outputs = model(input_ids, attention_mask)\n        predictions.extend(outputs.cpu().numpy())\n\npredictions = np.clip(predictions, 0, 5)\n\n\n# Make sure predictions are clipped between 0 and 5\npredictions = np.clip(predictions, 0, 5)\n\n# Build the submission DataFrame using correct column names\nsubmission_df = pd.DataFrame({\n    \"filename\": test_df[\"filename\"],\n    \"label\": predictions\n})\n\n# Save submission file\nsubmission_df.to_csv(\"submission.csv\", index=False)\nprint(\"‚úÖ Final submission file saved successfully!\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Summary Report**","metadata":{}},{"cell_type":"code","source":"from IPython.display import Markdown, display\n\ndef printmd(string):\n    display(Markdown(string))\n\nprintmd(\"## üìò Grammar Scoring Engine Report\")\nprintmd(\"**Model:** Whisper (ASR) + BERT + Regression\")\nprintmd(\"**Dataset:** 444 Train Audio Samples with MOS Grammar Scores\")\nprintmd(\"**ASR:** Whisper Base for transcript generation\")\nprintmd(\"**Text Modeling:** BERT + Linear Regression head\")\nprintmd(\"**Evaluation:** Pearson Correlation (per fold)\")\nprintmd(f\"**Best Pearson:** {max(val_pearsons):.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}